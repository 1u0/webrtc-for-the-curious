'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/01-what-why-and-how/','title':"What, Why and How",'section':"Docs",'content':"What is WebRTC. #  WebRTC is both an API and Protocol. The WebRTC protocol is a set of rules for two WebRTC agents to negotiate bi-directional secure communication. The WebRTC API was designed just for Javascript. This Javascript API then allows web developers to use the WebRTC protocol in the browser.\nA similar relationship would be HTTP and the fetch API. WebRTC the protocol would be HTTP, and WebRTC the API would be the fetch API.\nWebRTC is available in other APIs/languages besides Javascript. You can find servers and domain specific tools as well for WebRTC. All of these implementations use the WebRTC protocol so they can interact with each others.\nWhy should I learn WebRTC? #  These are the things that WebRTC will give you. This list is not exhaustive but is some of the things you may appreciate during your journey. Don\u0026rsquo;t worry if you don\u0026rsquo;t know some of these terms yet, this book will teach you them along tne way.\n Open Standard Multiple Implementations Available in Browsers Mandatory Encryption NAT Traversal Repurposed existing technology Congestion Control Sub-Second Latency  How does WebRTC (the protocol) Work #  This is a question that takes an entire book to explain. However, to start off we break it into four steps.\n Signaling Connecting Securing Communicating  These four steps happen sequentially. The prior step must be 100% successful for the subsequent one to even begin.\nOne peculiar fact about WebRTC is that each step is actually made up of many other protocols! To make WebRTC we stitch together many existing technologies. In that sense WebRTC is more a combination and configuration of well understood tech that has been around since the early 2000s.\nEach of these steps have dedicated chapters, but it is helpful to understand them at a high level first. Since they are dependant on each other it will help explain each steps purpose more.\nSignaling #  When a WebRTC Agent starts it has no idea who it is going to communicate with and what they are going to communicate about. Signaling solves this issue! Signaling is used to bootstrap the call so that two WebRTC agents can start communicating.\nSignaling uses an existing protocol SDP. SDP is a plain text protocol. Each SDP message is made up off key/value pairs and contains a list of \u0026lsquo;media sections\u0026rsquo;. The SDP that the two WebRTC Agents exchange contains details like.\n IPs and Ports that the agent is reachable on (candidates) How many audio and video tracks the agent wishes to send What audio and video codecs the agent supports Values used while connecting (uFrag/uPwd) Values used while securing (certificate fingerprint)  Connecting #  The two WebRTC Agents now know enough details to attempt to connect to each other. WebRTC then uses another established technology called ICE.\nICE (Interactive Connectivity Establishment) is a protocol that pre-dates WebRTC. ICE allows the establishment of a connection between two Agents. These Agents could be in the same network, or on the other side of the world. ICE is the solution to establishing a direct connection without a central server.\nThe real magic here is \u0026lsquo;NAT Traversal\u0026rsquo; and STUN/TURN Servers. These two concepts are all you need to communicate with an ICE Agent in another subnet. We will explore these topics in depth later.\nOnce ICE successfully connects, WebRTC then moves on to establishing an encrypted transport. This transport is used for the audio, video and data.\nSecuring #  Now that we have bi-directional communication (via ICE) we need to establish secure communication. This is done through two protocols that pre-date WebRTC. The first protocol is DTLS (Datagram Transport Layer Security) which is just TLS over UDP. TLS is the technology that powers HTTPS. The second protocol is SRTP (Secure Real-time Transport Protocol).\nFirst WebRTC connects by doing a DTLS handshake over the connection established by ICE. Unlike HTTPS WebRTC doesn\u0026rsquo;t use a central authority for certificates. Instead WebRTC just asserts that the certificate exchanged via DTLS matches the the fingerprint shared via signaling. This DTLS connection is then used for DataChannel messages.\nWebRTC then uses a different protocol for audio/video transmission called RTP. We secure our RTP packets using SRTP. We initialize our SRTP session by extracting the keys from the negotiated DTLS session. In a later chapter we discuss why media transmission has its own protocol.\nWe are done! You now have bi-directional and secure communication. If you have a stable connection between your WebRTC Agents this is all the complexity you may need. Unfortunately the real world has packet loss and bandwidth limits, and the next section is about how we deal with them.\nCommunicating #  We now have two WebRTC Agents with secure bi-directional communication. Lets start communicating! Again we use two pre-existing protocol RTP (Real-time Transport Protocol) and SCTP (Stream Control Transmission Protocol).\nRTP is used to carry media, and is encrypted using SRTP. The RTP protocol is quite minimal, but gives us what we need to implement real-time streaming. The important thing is that RTP gives flexibility to the developer so they can handle latency, loss and congestion as they please. We will discuss this further in the media chapter!\nThe final protocol in the stack is SCTP. SCTP is used to send DataChannel messages and those messages are encrypted with DTLS. SCTP allows many different delivery options for messages. You can optionally choose to have unreliable, out of order delivery so you can get the latency needed for real-time systems.\nWebRTC, a collection of protocols #  WebRTC solves a lot of problems. At first this may even seem over-engineered. The genius of WebRTC is really the humility. It didn\u0026rsquo;t assume it could solve everything better. Instead it embraced many existing single purpose technologies and bundled them together.\nThis allows us to examine and learn each part individually without being overwhelmed. A good way to visualize it is a \u0026lsquo;WebRTC Agent\u0026rsquo; is really just an orchestrator of many other protocols.\n  mermaid.initialize({ flowchart: { useMaxWidth:true } });  graph TB webrtc{WebRTC Agent} sctp{SCTP Agent} dtls{DTLS Agent} ice{ICE Agent} stun{STUN Protocol} turn{TURN Agent} srtp{SRTP Agent} sctp{SDP} rtp{RTP} rtcp{RTCP} webrtc -- ice webrtc -- dtls webrtc -- sctp webrtc -- srtp ice -- turn ice -- stun srtp -- rtcp srtp -- rtp How does WebRTC (the API) work #  This section shows how the Javascript API maps to the protocol. This isn\u0026rsquo;t meant as an extensive demo of the WebRTC API, but more to create a mental model of how it all ties together. If you aren\u0026rsquo;t familiar with either that is ok. This could be a fun section to return to as you learn more!\nnew PeerConnection #  The PeerConnection is the top level \u0026lsquo;WebRTC Session\u0026rsquo;. It contains all the protocols mentioned above. The subsystems are all allocated but nothing happens yet.\naddTrack #  addTrack creates a new RTP stream. A random SSRC will be generated for this stream. This stream will then be inside the Session Description generated by createOffer inside a media section. Each call to addTrack will create a new SSRC and media section.\nImmediately after a SRTP Session is established these media packets will start being sent via ICE after encrypted using SRTP.\ncreateDataChannel #  createDataChannel creates a new SCTP stream. If no SCTP association existed before one is created. By default SCTP is not enabled, but is only started when one side requests a data channel.\nImmediately after a DTLS Session is established the SCTP association will start sending packets via ICE and encrypted with DTLS.\ncreateOffer #  createOffer generates a Session Description of the local state to be shared with the remote peer.\nThe act of calling createOffer doesn\u0026rsquo;t change anything for the local peer.\nsetLocalDescription #  setLocalDescription commits any requested changes. addTrack, createDataChannel and similar calls are all temporary until this call. setLocalDescription is called with the value generated by createOffer.\nUsually after this call you will send the offer to the remote peer, and they will call setRemoteDescription with it.\nsetRemoteDescription #  setRemoteDescription is how we inform the local agent about the remote candidates state. This is how the act of \u0026lsquo;Signaling\u0026rsquo; is done with the Javascript API.\nWhen setRemoteDescription has been called on both sides the WebRTC Agents now have enough info to start communicating P2P!\naddicecandidate #  addIceCandidate allows a WebRTC agent to add more remote ICE Candidates whenever they want. This API sends the ICE Candidate right into the ICE subsystem and has no other effect on the greater WebRTC connection.\nontrack #  ontrack is a callback that is fired when a RTP packet is received from the remote peer. The incoming packets would have been declared in the Session Description that was passed to setRemoteDescription\nWebRTC uses the SSRC and looks up the associated MediaStream and MediaStreamTrack and fires this callback with these details populated.\noniceconnectionstatechange #  oniceconnectionstatechange is a callback that is fired that reflects the state of the ICE Agent. When you have network connectivity or when you become disconnected this is how you are notified.\nonstatechange #  onstatechange is a combination of ICE Agent and DTLS Agent state. You can watch this to be notified when ICE and DTLS have both completed successfully.\n"});index.add({'id':1,'href':'/docs/02-signaling/','title':"Signaling",'section':"Docs",'content':"Why do I need signaling? #  When you create a WebRTC agent it knows nothing about the other peer. It has no idea who it is going to connect with or what they are going to send! Signaling is the initial bootstrapping that makes the call possible. After these values are exchanged the WebRTC agents then can communicate directly with each other.\nSignaling messages are just text. The WebRTC agents don\u0026rsquo;t care how they are transported. They are commonly shared via Websockets, but not a requirement.\nHow does it work? #  WebRTC uses an existing protocol called the Session Description Protocol. Via this protocol the two WebRTC Agents will share all the state required to establish a connection. The protocol itself is simple to read and understand. The complexity comes from understanding all the values that WebRTC populates it with.\nThis protocol is not specific to WebRTC. We will learn the Session Description Protocol first without even talking about WebRTC. WebRTC only really takes advantage of a subset of the protocol so we are only going to cover what we need. After we understand the protocol we will move on to its applied usage in WebRTC.\nSession Description Protocol #  The Session Description Protocol is defined in RFC 4566. It is a key/value protocol with a newline after each value. It will feel similar to an ini file. A Session Description then contains an unlimited amount of Media Descriptions. Mentally you can model it as a Session Description contains an array of Media Descriptions.\nA Media Description usually maps to a single stream of media. So if you wanted to describe a call with three video streams and two audio tracks you would have five Media Descriptions.\nWhat does Key/Value mean #  Every line in a Session Description will start with a single character, this is your key. It will then be followed by an equal sign. Everything after that equal sign is the value. After the value is complete you will have a newline.\nThe Session Description Protocol defines all the keys that are valid. You can only use letters for keys as defined in the protocol. These keys all have significant meaning, which will be explained later.\nTake this Session Description excerpt.\na=my-sdp-value a=second-value You have two lines. Each with the key a. The first line has the value my-sdp-value, the second line has the value second-value.\nWebRTC only uses some keys #  Not all key values defined by the Session Description Protocol are used by WebRTC. The following are the only keys you need to understand. Don\u0026rsquo;t worry about fully understanding yet, but this will be a handy reference in the future.\n v - Version, should be equal to \u0026lsquo;0\u0026rsquo; o - Origin, contains a unique ID useful for renegotiations s - Session Name, should be equal to \u0026lsquo;-\u0026rsquo; t - Timing, should be equal to \u0026lsquo;0 0\u0026rsquo; m - Media Description, described in detail below a - Attribute, free text field this is the most common line in WebRTC c - Connection Data, should be equal to \u0026lsquo;IN IP4 0.0.0.0\u0026rsquo;  Media Descriptions #  A Session Description can contain an unlimited amount of Media Descriptions.\nA Media Description definition contains a list of formats. These formats map to RTP Payload Types. The actual codec is then defined by a Attribute with the value rtpmap in the Media Description. The importance of RTP and RTP Payload Types is discussed later in the Media chapter. Each Media Description then can contain an unlimited amount of attributes.\nTake this Session Description excerpt.\nv=0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4000 RTP/AVP 96 a=rtpmap:96 VP8/90000 a=my-sdp-value You have two Media Descriptions, one of type audio with fmt 111 and one of type video with fmt 96. The first Media Description has only one attribute. This attribute maps the Payload Type 111 to Opus. The second Media Description has two attributes. The first attribute maps the Payload Type 96 to be VP8, and the second attribute is just my-sdp-value\nFull Example #  The following brings all the concepts we have talked about together. These are all the features of the Session Description Protocol that WebRTC uses. If you can read this you can read any WebRTC Session Description!\nv=0 o=- 0 0 IN IP4 127.0.0.1 s=- c=IN IP4 127.0.0.1 t=0 0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4002 RTP/AVP 96 a=rtpmap:96 VP8/90000  v, o, s, c, t are defined but all have no effect on the WebRTC session. You have two Media Descriptions. One of type audio and one of type video. Each of those have one attribute. This attribute configures details of the RTP pipeline, which is discussed in the \u0026lsquo;Media Communication\u0026rsquo; chapter.  Session Description Protocol and WebRTC #  The next piece of the puzzle is understanding how WebRTC uses the Session Description Protocol.\nOffers and Answers #  WebRTC uses an offer/answer model. All this means is that one WebRTC Agent makes an \u0026lsquo;Offer\u0026rsquo; to start the call, and the other WebRTC Agents \u0026lsquo;Answers\u0026rsquo; if it is willing to accept what has been offered.\nThis gives the answerer a chance to reject codecs, Media Descriptions. This is how two peers can understand what they are willing to exchange.\nTransceivers #  Transceivers is a WebRTC specific concept that you will see in the API. What it is doing is exposing the \u0026lsquo;Media Description\u0026rsquo; to the Javascript API. Each Media Description becomes a Transceiver. Every time you create a Transceiver a new Media Description is added to the local Session Description.\nEach Media Description in WebRTC will have a direction attribute. This allows a WebRTC Agent to declare \u0026lsquo;I am going to send you this codec, but I am not willing to accept anything back\u0026rsquo;. There are four valid values\n send recv sendrecv inactive  Values used by WebRTC #  This list is not extensive, but this is a list of common attributes that you will see in a Session Description from a WebRTC Agent. Many of these values control the subsystems that we haven\u0026rsquo;t discussed yet.\ngroup:BUNDLE #  Bundling is the act of running multiple types of traffic over one connection. Some WebRTC implementations use a dedicated connection per media stream. Bundling should be preferred.\nfingerprint:sha-256 #  This is a hash of the certificate the peer is using for DTLS. After the DTLS handshake is completed you compare this to the actual certificate to confirm you are communicating with whom you expect.\nsetup: #  This controls the DTLS Agent behavior. This determines if it runs as a client or server after ICE has connected.\n setup:active - Run as DTLS Client setup:passive - Run as DTLS Server setup:actpass - Ask other WebRTC Agent to choose  ice-ufrag #  This is the user fragment value for the ICE Agent. Used for the authentication of ICE Traffic.\nice-pwd #  This is the password for the ICE Agent. Used for authentication of ICE Traffic.\nrtpmap #  This value is used to map a specific codec to a RTP Payload Type. Payload types are not static so every call the Offerer decides the Payload types for each codec.\nfmtp #  Defines additional values for one Payload Type. This is useful to communicate a specific video profile or encoder setting.\ncandidate #  This is an ICE Candidate that comes from the ICE Agent. This is one possible address that the WebRTC Agent is available on. These are fully explained in the next chapter.\nssrc #  A SSRC defines a single media stream track.\nlabel is the id for this individual stream. mslabel is the id for a container that can multiple streams inside of it.\nExamples #  The following if a complete Session Description generated by a WebRTC Client.\nv=0 o=- 3546004397921447048 1596742744 IN IP4 0.0.0.0 s=- t=0 0 a=fingerprint:sha-256 0F:74:31:25:CB:A2:13:EC:28:6F:6D:2C:61:FF:5D:C2:BC:B9:DB:3D:98:14:8D:1A:BB:EA:33:0C:A4:60:A8:8E a=group:BUNDLE 0 1 m=audio 9 UDP/TLS/RTP/SAVPF 111 c=IN IP4 0.0.0.0 a=setup:active a=mid:0 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:111 opus/48000/2 a=fmtp:111 minptime=10;useinbandfec=1 a=ssrc:350842737 cname:yvKPspsHcYcwGFTw a=ssrc:350842737 msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=ssrc:350842737 mslabel:yvKPspsHcYcwGFTw a=ssrc:350842737 label:DfQnKjQQuwceLFdV a=msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=sendrecv a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=end-of-candidates m=video 9 UDP/TLS/RTP/SAVPF 96 c=IN IP4 0.0.0.0 a=setup:active a=mid:1 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:96 VP8/90000 a=ssrc:2180035812 cname:XHbOTNRFnLtesHwJ a=ssrc:2180035812 msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=ssrc:2180035812 mslabel:XHbOTNRFnLtesHwJ a=ssrc:2180035812 label:JgtwEhBWNEiOnhuW a=msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=sendrecv a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=end-of-candidates This is what we now from this message\n We have two media sections, one audio and one video Each of those are a sendrecv Transceiver. We are getting two streams, and we can send two back. We have ICE Candidates and Authentication details so we can attempt to connect We have a certificate fingerprint, so we can have a secure call  Further Topics #  In later versions of this book the following topics will also be addressed. If you have more questions please submit a Pull Request!\n Renegotation Simulcast  "});index.add({'id':2,'href':'/docs/03-connecting/','title':"Connecting",'section':"Docs",'content':"Why do I need a dedicated subsystem for connecting? #  WebRTC will go to great lengths to achieve direct bi-directional communication between two WebRTC Agents. This connection style is also known as peer-to-peer. Establishing peer-to-peer connectivity can be difficult though. These agents could be in different networks with no direct connectivity!\nIn situations where direct connectivity does exist you can have other issues. In some cases your clients don\u0026rsquo;t speak the same network protocols (UDP \u0026lt;-\u0026gt; TCP) or maybe IP Versions (IPv4 \u0026lt;-\u0026gt; IPv6).\nBecause WebRTC has these attributes you get these advantages over traditional Client/Server technology.\nReduced Bandwidth Costs #  Since media communication happens directly between peers you don\u0026rsquo;t have to pay for transporting it.\nLower Latency #  Communication is faster when it is direct! When a user has to run everything through you server it makes things slower.\nSecure E2E Communication #  Direct Communication is more secure. Since users aren\u0026rsquo;t routing your data through your server they don\u0026rsquo;t even need to trust you won\u0026rsquo;t decrypt it.\nHow does it work? #  The process described above is ICE. Another protocol that pre-dates WebRTC.\nICE is a protocol that tries to find the best way to communicate between two ICE Agents. Each ICE Agents publishes the ways it is reachable, these are known as candidates. ICE then determines the best pairing of candidates.\nThe actual ICE Process is described in greater detail later in this chapter. To understand why ICE exists it is useful to understand what network behaviors were are overcoming.\nNetworking real world constraints #  ICE is all about overcoming the constraints of real world networks. Before we even explore the solution lets talk about the actual problems.\nNot in the same network #  Most of the time the other WebRTC Agent will not even be in the same network. A typical call is usually between two WebRTC Agents in different networks with no direct connectivity.\nBelow is a graph of two distinct networks, connected by the public internet. Then in each network you have two hosts.\n  mermaid.initialize({ flowchart: { useMaxWidth:true } });  graph TB subgraph netb [\"Network B (IP Address 5.0.0.2)\"] b3[\"Agent 3 (IP 192.168.0.1)\"] b4[\"Agent 4 (IP 192.168.0.1)\"] routerb[\"Router B\"] end subgraph neta [\"Network A (IP Address 5.0.0.1)\"] routera[\"Router A\"] a1[\"Agent 1 (IP 192.168.0.1)\"] a2[\"Agent 2 (IP 192.168.0.1)\"] end pub{Public Internet} routera--pub routerb--pub For the hosts in the same network it is very easy to connect. Communication between 192.168.0.1 -\u0026gt; 192.168.0.2 is easy to do! These two hosts can connect to each other without any outside help.\nHowever a host using Router B has no way to directly access anything behind Router A. A host using Router B could send traffic directly to Router A, but the request would end there. How does Router A know which host it should deliver the message too?\nProtocol Restrictions #  Some networks don\u0026rsquo;t allow UDP traffic at all, or maybe they don\u0026rsquo;t allow TCP. Some networks have a very low MTU. There are lots of variables that network administrators can change that can make communication difficult.\nFirewall/IDS Rules #  Another is \u0026lsquo;Deep Packet Inspection\u0026rsquo; and other intelligent filtering. Some network administrators will run software that tries to process every packet. Many times this software doesn\u0026rsquo;t understand WebRTC, so blocks because it doesn\u0026rsquo;t know what to do\nNAT Mapping #  NAT(Network Address Translation) Mapping is the magic that makes the connectivity of WebRTC possible. This is how WebRTC allows two peers in completely different subnets to communicate. It doesn\u0026rsquo;t use a relay, proxy or server.\nAgain we have a Agent 1 and Agent 2 and they are in different networks. However traffic is flowing completely through. Visualized that looks like.\ngraph TB subgraph netb [\"Network B (IP Address 5.0.0.2)\"] b2[\"Agent 2 (IP 192.168.0.1)\"] routerb[\"Router B\"] end subgraph neta [\"Network A (IP Address 5.0.0.1)\"] routera[\"Router A\"] a1[\"Agent 1 (IP 192.168.0.1)\"] end pub{Public Internet} a1-.-routera; routera-.-pub; pub-.-routerb; routerb-.-b2; To makes this communication happen you establish a NAT Mapping. Creating a NAT mapping will feel like an automated/config-less version of doing port forwarding in your router.\nThe downside to NAT Mapping is that that network behavior is inconsistent between networks. ISPs and hardware manufacturers may do it in different ways. In some cases network administrators may even disable it. The full range of behaviors is understood and observable, so a ICE Agent is able to confirm it created a NAT Mapping, and the attributes of the mapping.\nThe document that describes these behaviors is RFC 4787\nCreating a Mapping #  Creating a mapping is the easiest part. When you send a packet to an address outside your network, a mapping is created! A NAT Mapping is just an temporary public IP/Port that is allocated by your NAT. The outbound message will be rewritten to have its source address be the newly created mapping. If a message isn\u0026rsquo;t sent the the mapping it will be automatically routed back to the host inside the NAT.\nThe details around mappings is where it gets complicated.\nMapping Creation Behaviors #  Mapping creation fall into three different categories.\nEndpoint Independent Mapping #  One mapping is created for each sender inside the NAT. If you send two packets to two different remote addresses the NAT Mapping will be re-used. Both remote hosts would see see the same source IP/Port. If the remote hosts responded and it would be sent back to the same local listener.\nThis is the best case scenario. For a call to work at least one side MUST be of this type.\nAddress Dependent Mapping #  A new mapping is created every time you send to a new address. If you send two packets to different hosts two mappings will be created. If you send two packets to the same remote host, but different destination ports a new mapping will NOT be created.\nAddress and Port Dependent Mapping #  A new mapping is created if the remote IP or Port is different. If you send two packets to the same remote host, but different destination ports a new mapping will be created.\nMapping Filtering Behaviors #  Mapping filtering are the rules around who is allowed to use the mapping. They fall into three similar classifications.\nEndpoint Independent Filtering #  Anyone can use the mapping. You can share the mapping with multiple other peers and they coould all send traffic to it.\nAddress Dependent Filtering #  Only the host the mapping was created for can use the mapping. If you send a packet to host A it can respond back with as many packets as it wants. If host B attempts to send a packet to that mapping it will be ignored.\nAddress and Port Dependent Filtering #  Only the host and port the mapping was created for can use the mapping. If you send a packet to host A:5000 it can respond back with as many packets as it wants. If host A:5001 attempts to send a packet to that mapping it will be ignored.\nMapping Refresh #  It is recommended that if a mapping is unused for 5 minutes it should be destroyed. This is entirely up to the ISP or hardware manufacturer.\nSTUN #  STUN(Session Traversal Utilities for NAT) is a protocol that was created just for working with NATs. This is another technology pre-dates WebRTC (and ICE!). It is defined by RFC 5389, STUN defines the structure of packets. The STUN protocol is also used by ICE/TURN.\nSTUN is useful because it allows the programmatic creation of NAT Mappings. Before STUN we were able to create NAT Mappings, but we had no idea what the IP/Port of it was! STUN not only gives you the ability to create a mapping, but then you get the details so you can share it with others so they can send traffic to you via the mapping you created.\nLets start with a basic description of STUN. Later it will be extended later for TURN and ICE usage. For now we are just going to describe the Request/Response flow to create a mapping. Then we talk about how we get the details of it to share with others. This is the process that happens when you have a stun: server in your ICE urls for a WebRTC PeerConnection.\nProtocol Structure #  Every STUN packets begins with a STUN header, with the following structure\n 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |0 0| STUN Message Type | Message Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Magic Cookie | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | | Transaction ID (96 bits) | | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ STUN Message Type #  Each STUN packet has a type. For now we only care about the following.\n Binding Request - 0x0001 Binding Response - 0x0101  To create a NAT Mapping we make a Binding Request. Then the server responds with a Binding Response.\nMessage Length #  This is how long the Data section is. This section contains arbitrary data that is defined by the Message Type\nMagic Cookie #  The fixed value 0x2112A442, it helps distinguish STUN traffic from other protocols.\nTransaction ID #  96-bit identifier that uniquely identifies a request/response. This helps you pair up your requests and responses.\nData #  Data will contain a list of STUN attributes. A STUN Attribute has the following structure.\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type | Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Value (variable) .... +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ The STUN Binding Request uses no attributes.\nThe STUN Binding Response uses a XOR-MAPPED-ADDRESS (0x0020). This attribute contains an IP/Port. This is the IP/Port of the NAT Mapping that is created!\nCreate a NAT Mapping #  Creating a NAT Mapping using STUN just takes sending one request! You send a STUN Binding Request to the STUN Server. The STUN Server then responds with a STUN Binding Response. This STUN Binding Response will contain the Mapped Address. The Mapped Address is how the STUN Server sees you, and is your NAT Mapping. The Mapped Address is what you would share if you wanted someone to send packets to you.\nPeople will also call the Mapped Address your Public IP or Server Reflexive Candidate.\nDetermining NAT Type #  Unfortunately the Mapped Address might not be useful in all cases. If it is Address Dependent only the STUN server can send traffic back to you. If you shared it and another peer tried to send messsages in they will be dropped. This makes it useless for communicating with others.\nRFC5780 defines a method for running a test to determine your NAT Type. This would be useful because you would know ahead of time if direct connectivity was possible.\nTURN #  TURN (Traversal Using Relays around NAT) is defined in RFC5766 is the solution when direct connectivity isn\u0026rsquo;t possible. It could be because you have two NAT Types that are incompatible, or maybe can\u0026rsquo;t speak the same protocol! TURN is also important for privacy purposes. By running all your communication through TURN you obscure the clients actual address.\nTURN uses a dedicated server. This server acts as a proxy for a client. The client connects to a TURN Server and creates an Allocation. By creating a Allocation a client gets a temporary IP/Port/Protocol that can send into to get traffic back to the client. This new listener is known as the Relayed Transport Address. Think of it like a forwarding address, you give this out so others can send you traffic via TURN! For each user you give the Relay Transport Address you must create a \u0026lsquo;Permission\u0026rsquo; for.\nWhen you send outbound traffic via TURN it is sent via the Relayed Transport Address. When a remote peer gets traffic they see it coming from the TURN Server.\nTURN Lifecycle #  The following is everything that a client who wishes to create a TURN allocation has to do. Communicating with someone who is using TURN requires no changes. The other peer gets a IP/Port and they communicate with it like any other host.\nAllocations #  Allocations are at the core of TURN. A Allocation is basically a \u0026lsquo;TURN Session\u0026rsquo;. To create a TURN allocation you communicate with the TURN Server Transport Address (usually 3478)\nWhen creating an allocation you need to provide/decide the following\n Username/Password - Creating TURN allocations require authentication Allocation Transport - The Relayed Transport Address can be UDP or TCP Even-Port - You can request sequential ports for multiple allocations, not relevant for WebRTC  If the request succeeded you get a response with the TURN Server with the follow STUN Attributes in the Data section.\n XOR-MAPPED-ADDRESS - Mapped Address of the TURN Client. When someone sends data to the Relayed Transport Address this is where it is forwarded too. RELAYED-ADDRESS - This is the address that you give out to other clients. If someone sends a packet to this address it is relayed to the TURN Client. LIFETIME - How long until this TURN Allocation is destroyed. You can extend the lifetime by sending a Refresh request.  Permissions #  A remote host can\u0026rsquo;t send into your Relayed Transport Address until you create a permission for them. When you create a permission you are telling the TURN server that this IP/Port is allowed to send inbound traffic.\nThe remote host needs to give you the IP/Port as it appears to the TURN server. This means it should send a STUN Binding Request to the TURN Server. A common error case is that a remote host will send a STUN Binding Request to a different Server. They will then ask you to create a permission for this IP.\nLets say you want to create a permission for a host behind a Address Dependent Mapping. If you generate the Mapped Address from a different TURN server all inbound traffic will be dropped. Everytime they communicate with a different host it generates a new mapping.\nSendIndication/ChannelData #  These two messages are for the TURN Client to send messages to a remote peer.\nSendIndication is a self contained message. Inside it is the data you wish to send, and who you wish to send it too. This is wasteful if you are sending a lot of messages to a remote peer. If you send 1,000 messages you will repeat their IP Address 1,000 times!\nChannelData allows you to send data, but not repeat an IP Address. You create a Channel with a IP/Port. You then send with the ChannelId, and the IP/Port is populated server side. This is the better choice if you are sending lots of messages.\nRefreshing #  Allocations will destroy themselves automatically. The TURN Client must refresh them sooner then the LIFETIME given when creating the allocation.\nTURN Usage #  TURN Usage exists in two forms. Usually you have one peer acting as a \u0026lsquo;TURN Client\u0026rsquo; and the other side communicating directly. In bad cases you might have TURN Usage on both sides because of improper setup.\nThese diagrams help illustrate what that would look like.\nOne TURN Allocations for Communication #  graph TB subgraph turn [\"TURN Allocation\"] serverport[\"Server Transport Address\"] relayport[\"Relayed Transport Address\" ] end turnclient{TURN Client} peer{UDP Client} turnclient--|\"ChannelData (To UDP Client)\"|serverport serverport--|\"ChannelData (From UDP Client)\"|turnclient peer--|\"Raw Network Traffic (To TURN Client)\"|relayport relayport--|\"Raw Network Traffic (To UDP Client)\"|peer Two TURN Allocations for Communication #  graph TB subgraph turna[\"TURN Allocation A\"] serverportA[\"Server Transport Address\"] relayportA[\"Relayed Transport Address\" ] end subgraph turnb[\"TURN Allocation B\"] serverportB[\"Server Transport Address\"] relayportB[\"Relayed Transport Address\" ] end turnclientA{TURN Client A} turnclientB{TURN Client B} turnclientA--|\"ChannelData\"|serverportA serverportA--|\"ChannelData\"|turnclientA turnclientB--|\"ChannelData\"|serverportB serverportB--|\"ChannelData\"|turnclientB relayportA--|\"Raw Network Traffic\"|relayportB relayportB--|\"Raw Network Traffic\"|relayportA ICE #  ICE (Interactive Connectivity Establishment) is how WebRTC connects two Agents. Defined in RFC8445 this is another technology that pre-dates WebRTC! ICE is a protocol for establishing connectivity. It determines all the possible routes between the two peers, and then ensures you stay connected.\nThese routes are known as Candidate Pairs, which is a pairing of a local and remote address. This where STUN and TURN comes into play with ICE. These addresses can be your local IP Address, NAT Mapping or Relayed Transport Address. Each side gathers all the addresses they want to use, exchange them and then attempt to connect!\nTwo ICE Agents communicate using the STUN Protocol. They send STUN packets to each other to establish connectivity. After connectivity is established they can send whatever they want. It will feel like just using a normal socket.\nCreating an ICE Agent #  An ICE Agent is either Controlling or Controlled. The Controlling Agent is the one that decides the selected Candidate Pair.\nEach side must have a user fragment and password. These two values must be exchanged before connectivity checks to even begin. The user fragment is sent in plain text and is useful for demuxing multiple ICE Sessions. The password is used to generate a MESSAGE-INTEGRITY attribute. At the end of each STUN packet there is an attribute that is a hash of the entire packet using the password as a key. This is used to authenticate the packet and ensure it hasn\u0026rsquo;t been tamppered with.\nFor WebRTC all these values are distributed via the Session Description as described in the previous chapter.\nCandidate Gathering #  We now need to gather all the possible address we are reachable at. These addresses are known as candidates. These candidates are also distributed via the Session Description.\nHost #  A Host candidate is listening directly on a local interface. This can either be UDP or TCP.\nHost (mDNS) #  A mDNS candidate is similar to a host candidate, but the IP address is obscured. Instead of informing the other side about your IP Address you give them a UUID. You then set-up a multicast listener, and respond if anyone requests the UUID you published.\nIf you are in the same network as the Agent you can find each other via Multicast. If you aren\u0026rsquo;t in the same network you will be unable to connect.\nThis is useful for privacy purposes. Before a user could find out your local IP address via WebRTC, now they only get a random UUID.\nServer Reflexive #  A Server Reflexive candidate is generated by doing a STUN Binding Request to a STUN Server.\nWhen you get the STUN Binding Response the XOR-MAPPED-ADDRESS is your Server Reflexive Candidate.\nPeer Reflexive Candidates #  A Peer Reflexive candidate is when you get an inbound request from an address that isn\u0026rsquo;t know to you. Since ICE is an authenticated protocol you know the traffic is valid. This just means the remote peer is communicating with you from an address it didn\u0026rsquo;t know about.\nThis commonly happens when a Host Candidate communicates with a Server Reflexive Candidate. A new NAT Mapping was created because you are communicating outside your subnet.\nRelay #  A Relay Candidate is generated by using a TURN Server.\nAfter the initial handshake with the TURN Server you are given a RELAYED-ADDRESS, this is your Relay Candidate.\nConnectivity Checks #  We now know the remote agents user fragment, password and candidates. We can now attempt to connect! Every candidate is paired with each other. So if you have 3 candidates on each side, you now have 9 candidate pairs.\nVisually it looks like this graph LR subgraph agentA[\"ICE Agent A\"] hostA{Host Candidate} serverreflexiveA{Server Reflexive Candidate} relayA{Relay Candidate} end style hostA fill:#ECECFF,stroke:red style serverreflexiveA fill:#ECECFF,stroke:green style relayA fill:#ECECFF,stroke:blue subgraph agentB[\"ICE Agent B\"] hostB{Host Candidate} serverreflexiveB{Server Reflexive Candidate} relayB{Relay Candidate} end hostA --- hostB hostA --- serverreflexiveB hostA --- relayB linkStyle 0,1,2 stroke-width:2px,fill:none,stroke:red; serverreflexiveA --- hostB serverreflexiveA --- serverreflexiveB serverreflexiveA --- relayB linkStyle 3,4,5 stroke-width:2px,fill:none,stroke:green; relayA --- hostB relayA --- serverreflexiveB relayA --- relayB linkStyle 6,7,8 stroke-width:2px,fill:none,stroke:blue; Candidate Selection #  The Controlling and Controlled Agent both start sending traffic on each pair. This is needed if one Agent is behind a Address Dependent Mapping, this will cause a Peer Reflexive Candidate to be created.\nEach Candidate Pair that saw network traffic is then promoted to a Valid Candidate pair. The Controlling Agent then takes one Valid Candidate pair and nominates it. This becomes the Nominated Pair. The Controlling and Controlled Agent then attempt one more round of bi-directional communication. If that succeeds the Nominated Pair becomes the Selected Candidate Pair! This is used for the rest of the session.\nRestarts #  If the Selected Candidate Pair stops working for any reason (NAT Mapping Expires, TURN Server crashes) the ICE Agent will go to Failed. Both Agents can be restarted and do the whole process over again.\n"});index.add({'id':3,'href':'/docs/04-securing/','title':"Securing",'section':"Docs",'content':"What security does WebRTC have? #  Every WebRTC connection is authenticated and encrypted. You can be confident that a 3rd paert can\u0026rsquo;t what you are sending. They also can\u0026rsquo;t insert bogus messages. You can also be sure the WebRTC Agent that generated the Session Description is the one you are communicating with.\nIt is very important that no one tampers with those messages. It is ok if a 3rd party reads the Session Description in transit. However WebRTC has no protection against it being modified. An attacker could MITM you by changing ICE Candidates and the Certificate Fingerprint.\nHow does it work? #  WebRTC\nSecurity 101 #  To understand the technology presented in this chapter you will need to understand these first. Cryptography is a tricky subject so would be worth consulting other sources also!\n Cipher Hash Plaintext/Ciphertext RSA ECDSA Perfect Forward Secrecy Diffie-Helman Public/Private Key Certificate  DTLS #  SRTP #  Tying it all together #  "});index.add({'id':4,'href':'/docs/05-media-communication/','title':"Media Communication",'section':"Docs",'content':"Audio and Video Communication #  RTP/RTCP #  Protocol Basics Loss and Error Resilience Congestion Control\n"});index.add({'id':5,'href':'/docs/06-data-communication/','title':"Data Communication",'section':"Docs",'content':"SCTP #  "});index.add({'id':7,'href':'/docs/08-debugging/','title':"Debugging",'section':"Docs",'content':"Debugging #  Reduce Surface Area #  Network Debugging #  Media Debugging #  Data Debugging #  "});index.add({'id':8,'href':'/docs/09-history-of-webrtc/','title':"History",'section':"Docs",'content':"History #  This section is ongoing and we don’t have all the facts yet. We are conducting interviews and build a history of digital communication.\nPre-RTP #  RTP #  SDP #  ICE #  SRTP #  SCTP #  DTLS #  "});index.add({'id':9,'href':'/docs/10-faq/','title':"FAQ",'section':"Docs",'content':"FAQ #  "});})();