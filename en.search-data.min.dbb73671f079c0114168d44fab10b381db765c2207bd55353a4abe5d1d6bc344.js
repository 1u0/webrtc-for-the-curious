'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':0,'href':'/docs/01-what-why-and-how/','title':"What, Why and How",'section':"Docs",'content':"What is WebRTC. #  WebRTC is both an API and Protocol. The WebRTC protocol is a set of rules for two agents to negotiate bi-directional secure communication. The WebRTC API was designed just for Javascript. This Javascript API then allows web developers to use the WebRTC protocol in the browser.\nA similar relationship would be HTTP and the fetch API. WebRTC the protocol would be HTTP, and WebRTC the API would be the fetch API.\nMany other APIs besides Javascript, servers and tools exist for WebRTC. All of these implementations can interact with each others.\nWhy should I learn WebRTC? #  These are the things that WebRTC will give you. This list is not exhaustive but is some of the things you may appreciate during your journey. Don\u0026rsquo;t worry if you don\u0026rsquo;t know some of these terms yet, this book will teach you them along tne way.\n Open Standard Multiple Implementations Available in Browsers Mandatory Encryption NAT Traversal Repurposed existing technology Congestion Control Sub-Second Latency  How does WebRTC (the protocol) Work #  This is a question that takes an entire book to explain. However, to start off we break it into four steps.\n Signaling Connecting Securing Communicating  These four steps happen sequentially. The prior step must be 100% successful for the subsequent one to even begin. At a high level this is what each one of these steps is accomplishing.\nOne peculiar fact about WebRTC is that it actually made up of many other protocols! To make WebRTC we stitch together many existing technologies. In that sense WebRTC is more a combination and configuration of well understood tech that has been around since the early 2000s.\nEach of these steps have dedicated chapters, but it is helpful to understand them at a high level first. Since they are dependant on each other it will help explain each steps purpose more.\nSignaling #  When a WebRTC Agent starts it has no idea who it is going to communicate with and what they are going to communicate about. Signaling solves this issue! Signaling is used to bootstrap the call so that the two WebRTC agents can start communicating directly.\nSignaling uses an existing protocol SDP. SDP is a plain text buffer made up off key/value pairs and contains a list of \u0026lsquo;media sections\u0026rsquo;. The SDP that the two WebRTC Agents exchange contains details like.\n IPs and Ports that the agent is reachable on (candidates) How many audio and video tracks the agent wishes to send What audio and video codecs the agent supports Values used while connecting (uFrag/uPwd) Values used while securing (certificate fingerprint)  Connecting #  The two WebRTC Agents now know enough details to attempt to connect to each other. WebRTC again uses an existing technology called ICE.\nICE (Interactive Connectivity Establishment) is a protocol that pre-dates WebRTC. ICE allows the establishment of a connection between two Agents. These Agents could be in the same network, or on the other side of the world. ICE is the solution to establishing a direct connection without a central server.\nThe real magic here is \u0026lsquo;NAT Traversal\u0026rsquo; and TURN Servers. These two concepts are all you need to communicate with an IP/Port in another subnet. This is where STUN and TURN come into play. We will explore these topics in depth later.\nOnce ICE successfully connects, WebRTC then moves on to establishing an encrypted transport. This transport is used for the audio, video and data.\nSecuring #  Now that we have bi-directional communication (via ICE) we need to establish secure communication. This is done through two protocols that pre-date WebRTC. The first protocol is DTLS (Datagram Transport Layer Security) which is just TLS over UDP. TLS is the technology that powers HTTPS. The second protocol is SRTP (Secure Real-time Transport Protocol).\nFirst WebRTC connects by doing a DTLS handshake over the connection established by ICE. Unlike HTTPS WebRTC doesn\u0026rsquo;t use a central authority for certificates. Instead WebRTC just asserts that the certificate exchanged via DTLS matches the the fingerprint shared via signaling. This DTLS connection is then used for DataChannel messages.\nWebRTC then uses a different protocol for audio/video transmission called RTP. We secure our RTP packets using SRTP. We initialize our SRTP session by extracting the keys from the negotiated DTLS session. In a later chapter we discuss why media transmission has its own protocol.\nWe are done! You now have bi-directional and secure communication. If you have a stable connection between your WebRTC Agents this is all the complexity you may need. Unfortunately the real world has packet loss and bandwidth limits, and the next section is about how we deal with them.\nCommunicating #  We now have two WebRTC Agents with secure bi-directional communication. Lets start communicating! Again we use two pre-existing protocol RTP (Real-time Transport Protocol) and SCTP (Stream Control Transmission Protocol).\nRTP is used to carry media, and is encrypted using SRTP. The RTP protocol is quite minimal, but gives us what we need to implement real-time streaming. The important thing is that RTP gives flexibility to the developer so they can handle latency, loss and congestion as they please. We will discuss this further in the media chapter!\nThe final protocol in the stack is SCTP. SCTP is used to send DataChannel messages and those messages are encrypted with DTLS. SCTP allows many different delivery options for messages. You can optionally choose to have unreliable, out of order delivery so you can get the latency needed for real-time systems.\nWebRTC, a collection of protocols #  TODO a diagram of protocols working together\nWebRTC solves a lot of problems. At first this may even seem over-engineered. The genius of WebRTC is really the humility. It didn\u0026rsquo;t assume it could solve everything better. Instead it embraced many existing single purpose technologies and bundled them together.\nThis allows us to examine and learn each part individually without being overwhelmed.\nHow does WebRTC (the API) work #  This section shows how the Javascript API maps to the protocol. This isn\u0026rsquo;t meant as an extensive demo of the WebRTC API, but more to create a mental model of how it all ties together. If you aren\u0026rsquo;t familiar with either that is ok. This is a fun section to return to as you learn more!\nnew PeerConnection #  The PeerConnection is the top level \u0026lsquo;WebRTC Session\u0026rsquo;. It contains all the protocols mentioned above. The subsystems are all allocated but nothing happens yet.\naddTrack #  addTrack creates a new RTP stream. A random SSRC will be generated for this stream. This stream will then be inside the Session Description generated by createOffer inside a media section. Each call to addTrack will create a new SSRC and media section.\nImmediately after a SRTP Session is established these media packets will start being sent via ICE after encrypted using SRTP.\ncreateDataChannel #  createDataChannel creates a new SCTP stream. If no SCTP assocation existed before one is created. By default SCTP is not enabled, but is only started when one side requests a data channel.\nImmediately after a DTLS Session is established the SCTP assocation will start sending packets via ICE and encrypted with DTLS.\ncreateOffer #  createOffer generates a Session Description of the local state to be shared with the remote peer.\nThe act of calling createOffer doesn\u0026rsquo;t change anything for the local peer.\nsetLocalDescription #  setLocalDescription commits any requsted changes. addTrack, createDataChannel and similar calls are all temporary until this call. setLocalDescription is called with the value generated by createOffer.\nUsually after this call you will send the offer to the remote peer, and they will call setRemoteDescription with it.\nsetRemoteDescription #  setRemoteDescription is how we inform the local agent about the remote candidates state. This is how the act of \u0026lsquo;Signaling\u0026rsquo; is done with the Javascript API.\nWhen setRemoteDescription has been called on both sides the WebRTC Agents now have enough info to start communicating P2P!\naddicecandidate #  addIceCandidate allows a WebRTC agent to add more remote ICE Candidates whenever they want. This API sends the ICE Candidate right into the ICE subsystem and has no other effect on the greater WebRTC connection.\nontrack #  ontrack is a callback that is fired when a RTP packet is received from the remote peer. The incoming packets would have been declared in the Session Description that was passed to setRemoteDescription\nWebRTC uses the SSRC and looks up the associated MediaStream and MediaStreamTrack and fires this callback with these details populated.\noniceconnectionstatechange #  oniceconnectionstatechange is a callback that is fired that reflects the state of the ICE Agent. When you have network connectivity or when you become disconnected this is how you are notified.\nonstatechange #  onstatechange is a combination of ICE and DTLS state. You can watch this to be notified when ICE and DTLS has completed successfully.\n"});index.add({'id':1,'href':'/docs/02-signaling/','title':"Signaling",'section':"Docs",'content':"Why do I need signaling? #  When you create a WebRTC agent it knows nothing about the other peer. It has no idea who it is going to connect with or what they are going to send! Signaling is the inital bootstrapping that makes the call possible. After these values are exhanged the WebRTC agents then can communicate directly with each other.\nSignaling messages are just text. The WebRTC agents don\u0026rsquo;t care how they are transported. They are commonly shared via Websockets, but not a requirement.\nHow does it work? #  WebRTC uses an existing protcol called the Session Description Protocol. Via this protocol the two WebRTC Agents will share all the state required to establish a connection. The protocol itself is simple to read and understand. The complexity comes from understanding all the values that WebRTC populates it with.\nThis protocol is not specific to WebRTC, so we can learn the Session Description Protocol first without even talking about WebRTC. WebRTC only really takes advantage of a subset of the protcol so we are only going to cover that. After we understand the protocol we will move on to its applied usage in WebRTC.\nSession Description Protocol #  The Session Description Protocol is defined in RFC 4566. It is a key/value protocol with a newline after each value. It will feel similar to an ini file. A Session Description then contains an unlimited amount of Media Descriptions. Mentally you can model it as a Session Description contains an array of Media Descriptions.\nA Media Description usually maps to a single stream of media. So if you wanted to describe a call with three video streams and two audio tracks you would have five Media Descriptions.\nWhat does Key/Value mean #  Every line in a Session Description will start with a single character, this is your key. It will then be followed by an equal sign. Everything after that equal sign is the value. After the value is complete you will have a newline.\nThe Session Description Protocol defines all the keys that are valid. You can only use letters for keys as defined bt the protocol. These keys all have significant meaning, which will be explained later.\nTake this Session Description excerpt.\na=my-sdp-value a=second-value You have two lines. Each with the key a. The first line has the value my-sdp-value, the second line has the value second-value.\nWebRTC only uses some keys #  Not all key values defined by the Session Description Protocol are used by WebRTC. The following are the only keys you need to understand. Don\u0026rsquo;t worry about fully understanding yet, but this will be a handy reference in the future.\n v - Version, should be equal to \u0026lsquo;0\u0026rsquo; o - Origin, contains a unique ID useful for renegotiations s - Session Name, should be equal to \u0026lsquo;-\u0026rsquo; t - Timing, should be equal to \u0026lsquo;0 0\u0026rsquo; m - Media Description, described in detail below a - Attribute, free text field this is the most common line in WebRTC c - Connection Data, should be equal to \u0026lsquo;IN IP4 0.0.0.0\u0026rsquo;  Media Descriptions #  A Session Description can contain an unlimited amount of Media Descriptions.\nA Media Description definition contains a list of formats. These formats map to RTP Payload Types. The actual codec is then defined by a Attribute with the value rtpmap in the Media Description. The importance of RTP and RTP Payload Types is discussed later in the Media chapter. Each Media Description then can contain an unlimited amount of attributes.\nTake this Session Description excerpt.\nv=0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4000 RTP/AVP 96 a=rtpmap:96 VP8/90000 a=my-sdp-value You have two Media Descriptions, one of type audio with fmt 111 and one of type video with fmt 96. The first Media Description has only one attribute. This attribute maps the Payload Type 111 is Opus. The second Media Description has two attributes. The first attribute maps the Payload Type 96 to be VP8, and the second attribute is just my-sdp-value\nFull Example #  The following brings all the concepts we have talked about together. These are all the features of the Session Description Protocol that WebRTC uses. If you can read this you can read any WebRTC Session Description!\nv=0 o=- 0 0 IN IP4 127.0.0.1 s=- c=IN IP4 127.0.0.1 t=0 0 m=audio 4000 RTP/AVP 111 a=rtpmap:111 OPUS/48000/2 m=video 4002 RTP/AVP 96 a=rtpmap:96 VP8/90000  v, o, s, c, t are defined but all have no effect on the WebRTC session. You have two Media Descriptions. One of type audio and one of type video. Each of those have one attribute. This attribute configures details of the RTP pipeline, which is discussed in the \u0026lsquo;Media Communication\u0026rsquo; chapter.  Session Description Protocol and WebRTC #  The next piece of the puzzle is understanding how WebRTC uses the Session Description Protocol.\nOffers and Answers #  WebRTC uses an offer/answer model. All this means is that one WebRTC Agent makes an \u0026lsquo;Offer\u0026rsquo; to start the call, and the other WebRTC Agents \u0026lsquo;Answers\u0026rsquo; if it is willing to accept what has been offered.\nThis gives the answerer a chance to reject codecs, Media Descriptions etc\u0026hellip; that it is not willing to accept.\nTransceivers #  Transceivers is a WebRTC specific concept that you will see in the API. What it is doing is exposing the \u0026lsquo;Media Description\u0026rsquo; to the Javascript API. Each Media Description becomes a Transceiver. Every time you create a Transceiver a new Media Description is added to the local Session Description.\nEach Media Description in WebRTC will have a direction attribute. This allows a WebRTC Agent to declare \u0026lsquo;I am going to send you this codec, but I am not willing to accept anything back\u0026rsquo;. There are four valid values\n send recv sendrecv inactive  Values used by WebRTC #  This list is not extensive, but this is a list of common attributes that you will see in a Session Description from a WebRTC Agent. Many of these values control the subsystems that we haven\u0026rsquo;t discussed yet.\ngroup:BUNDLE #  Bundling is the act of running multiple types of traffic over one connection. Some WebRTC implementations use a dedicated connection per media stream. Bundling should be preferred.\nfingerprint:sha-256 #  This is a hash of the certificate the peer is using for DTLS. After the DTLS handshake is completed you compare this to the actual certificate to confirm you are communicating with whom you expect.\nsetup: #  This controls the DTLS Agent behavior. This determines if it runs as a client or server after ICE has connected.\n setup:active - Run as DTLS Client setup:passive - Run as DTLS Server setup:actpass - Ask other WebRTC Agent to choose  ice-ufrag #  This is the user fragment value for the ICE Agent. Used for the authentication of ICE Traffic.\nice-pwd #  This is the password for the ICE Agent. Used for authentication of ICE Traffic.\nrtpmap #  This value is used to map a specific codec to a RTP Payload Type. Payload types are not static so every call the Offerer decides the Payload types for each codec.\nfmtp #  Defines additional values for one Payload Type. This is useful to communicate a specific video profile or encoder setting.\ncandidate #  This is an ICE Candidate that comes from the ICE Agent. This is one possible address that the WebRTC Agent is available on. These are fully explained in the next chapter.\nssrc #  A SSRC defines a single media stream track.\nlabel is the id for this individual stream. mslabel is the id for a container that can multiple streams inside of it.\nExamples #  The following if a complete Session Description generated by a WebRTC Client.\nv=0 o=- 3546004397921447048 1596742744 IN IP4 0.0.0.0 s=- t=0 0 a=fingerprint:sha-256 0F:74:31:25:CB:A2:13:EC:28:6F:6D:2C:61:FF:5D:C2:BC:B9:DB:3D:98:14:8D:1A:BB:EA:33:0C:A4:60:A8:8E a=group:BUNDLE 0 1 m=audio 9 UDP/TLS/RTP/SAVPF 111 c=IN IP4 0.0.0.0 a=setup:active a=mid:0 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:111 opus/48000/2 a=fmtp:111 minptime=10;useinbandfec=1 a=ssrc:350842737 cname:yvKPspsHcYcwGFTw a=ssrc:350842737 msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=ssrc:350842737 mslabel:yvKPspsHcYcwGFTw a=ssrc:350842737 label:DfQnKjQQuwceLFdV a=msid:yvKPspsHcYcwGFTw DfQnKjQQuwceLFdV a=sendrecv a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=end-of-candidates m=video 9 UDP/TLS/RTP/SAVPF 96 c=IN IP4 0.0.0.0 a=setup:active a=mid:1 a=ice-ufrag:CsxzEWmoKpJyscFj a=ice-pwd:mktpbhgREmjEwUFSIJyPINPUhgDqJlSd a=rtcp-mux a=rtcp-rsize a=rtpmap:96 VP8/90000 a=ssrc:2180035812 cname:XHbOTNRFnLtesHwJ a=ssrc:2180035812 msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=ssrc:2180035812 mslabel:XHbOTNRFnLtesHwJ a=ssrc:2180035812 label:JgtwEhBWNEiOnhuW a=msid:XHbOTNRFnLtesHwJ JgtwEhBWNEiOnhuW a=sendrecv a=candidate:foundation 1 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 2 udp 2130706431 192.168.1.1 53165 typ host generation 0 a=candidate:foundation 1 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=candidate:foundation 2 udp 1694498815 1.2.3.4 57336 typ srflx raddr 0.0.0.0 rport 57336 generation 0 a=end-of-candidates This is what we now from this message\n We have two media sections, one audio and one video Each of those are a sendrecv Transceiver. We are getting two streams, and we can send two back. We have ICE Candidates and Authentication details so we can attempt to connect We have a certificate fingerprint, so we can have a secure call  Further Topics #  In later versions of this book the following topics will also be addressed. If you have more questions please submit a Pull Request!\n Renegotation Simulcast  "});index.add({'id':2,'href':'/docs/03-connecting/','title':"Connecting",'section':"Docs",'content':"Why do I need a dedicated subsystem for connecting? #  WebRTC will go to great lengths to achieve direct bi-directional communication between two WebRTC Agents. These agents may even be in different networks with no direct communication between agents, by using NAT Traversal WebRTC can make communication happen. NAT Traversal is a networking technique that enables communication between two peers that can\u0026rsquo;t directly connect.\nIn situations where direct connectivity doesn\u0026rsquo;t exist and NAT Traversal fails WebRTC has other techniques. You can then use a TURN server to communicate across protocols (UDP \u0026lt;-\u0026gt; TCP) and versions (IPv4 \u0026lt;-\u0026gt; IPv6).\nBecause WebRTC has these attributes you get these advantages over traditional Client/Server technology.\nReduced Bandwidth Costs #  Since media communication happens directly during peers you don\u0026rsquo;t have to pay for transporting it.\nLower Latency #  Communication is faster when it is direct! When a user had to run everything through you server it makes things slower.\nSecure E2E Communication #  Direct Communication is more secure. Since users aren\u0026rsquo;t routing your data through your server they don\u0026rsquo;t even need to trust you won\u0026rsquo;t decrypt it.\nHow does it work? #  The process described above is ICE. Another protocol that pre-dates WebRTC.\nICE is a protocol that tries to find the best way to communicate between two ICE Agents. Each ICE Agents publishes the ways it is reachable, these are known as candidates. ICE then determines the best candidate pairing of candidates.\nThe actual ICE Process is described in greater detail later in this chapter. To understand why ICE exists it is useful to understand what network behaviors were are overcoming.\nNetworking real world constraints #  ICE is all about overcoming the constraints of real world networks. Before we even explore the solution lets talk about the actual problems.\nNot in the same network #  Most of the time the other WebRTC Agent will not even be in the same network. A typical call is usually between two WebRTC Agents in different networks with no direct connectivity.\nBelow is a graph of two distinct networks, connected by the public internet. Then in each network you have two hosts.\n  mermaid.initialize({ flowchart: { useMaxWidth:true } });  graph TB subgraph netb [\"Network B (IP Address 5.0.0.2)\"] b3[\"Agent 3 (IP 192.168.0.1)\"] b4[\"Agent 4 (IP 192.168.0.1)\"] routerb[\"Router B\"] end subgraph neta [\"Network A (IP Address 5.0.0.1)\"] routera[\"Router A\"] a1[\"Agent 1 (IP 192.168.0.1)\"] a2[\"Agent 2 (IP 192.168.0.1)\"] end pub{Public Internet} routera--pub routerb--pub For the hosts in the same network it is very easy to connect. 192.168.0.1 -\u0026gt; 192.168.0.2 is easy to do! However a host using Router B has no way to directly access anything using Router A. A host using Router B could send traffic directly to Router A, but the request would end there.\nProtocol Restrictions #  Some networks don\u0026rsquo;t allow UDP traffic at all, or maybe they don\u0026rsquo;t allow TCP. Some networks have a very low MTU. There are lots of variables that network administrators can change that can make communication difficult.\nFirewall/IDS Rules #  Another is \u0026lsquo;Deep Packet Inspection\u0026rsquo; and other intelligent filtering. Some network administrators will run software that tries to process every packet. Many times this software doesn\u0026rsquo;t understand WebRTC, so blocks because it doesn\u0026rsquo;t know what to do\nNAT Mapping #  NAT(Network Address Translation) Mapping is the magic that makes the connectivity of WebRTC possible, even when the peers can\u0026rsquo;t access each other on their own. With this you can have two peers in completely different networks communicating directly.\nAgain we have a Agent 1 and Agent 2 and they are in different networks. However traffic is flowing completely through. Visualized that looks like.\ngraph TB subgraph netb [\"Network B (IP Address 5.0.0.2)\"] b2[\"Agent 2 (IP 192.168.0.1)\"] routerb[\"Router B\"] end subgraph neta [\"Network A (IP Address 5.0.0.1)\"] routera[\"Router A\"] a1[\"Agent 1 (IP 192.168.0.1)\"] end pub{Public Internet} a1-.-routera; routera-.-pub; pub-.-routerb; routerb-.-b2; To makes this possible you need to establish a NAT Mapping first. NAT mapping will feel like an automated/config-less version of doing port forwarding in your router.\nThe downside to NAT Mapping is that that network behavior is inconsistent between networks. ISPs and hardware manufacturers do it in different ways for their own reasons. In some cases network administrators may even disable it. The full range of behaviors is understood and observable, so a ICE Agent is able to confirm it created a NAT Mapping, and the attributes of the mapping.\nThe document that describes these behaviors is RFC 4787\nCreating a Mapping #  Creating a mapping is the easiest part. When you send a packet to an address outside your network, a mapping is created! If the server then responds to your request the response will be delivered back to the host that sent it. The server can respond with multiple packets back to your single message.\nThe details around mappings is where it gets complicated.\nMapping Creation Behaviors #  These are the rules for when a new mapping is created. They fall into three different categories.\nEndpoint Independent Mapping #  One mapping is created for each sender inside the NAT. If you send two packets to different remote addresses the NAT Mapping will be re-used. Both remote hosts could then respond and it would be sent back to the same local listener.\nThis is the best case scenario. For a call to work at least one side MUST be of this type.\nAddress Dependent Mapping #  A new mapping is created every time you send to a new address. If you send two packets to different hosts two mappings will be created. If you send two packets to the same remote host, but different destination ports a new mapping will NOT be created.\nAddress and Port Dependent Mapping #  A new mapping is created if the remote IP or Port is different. If you send two packets to the same remote host, but different destination ports a new mapping will be created.\nMapping Filtering Behaviors #  Mapping filtering are the rules around who is allowed to use the mapping. They fall into three similar classifications.\nEndpoint Independent Filtering #  Anyone can use the mapping. After you create the mapping by sending a packet that mapping can be used by anyone on the internet.\nAddress Dependent Filtering #  Only the host the mapping was created for can use the mapping. If you send a packet to host A it can respond back with as many packets as it wants. If host B attempts to send a packet to that mapping it will be ignored.\nAddress and Port Dependent Filtering #  Only the host and port the mapping was created for can use the mapping. If you send a packet to host A:5000 it can respond back with as many packets as it wants. If host A:5001 attempts to send a packet to that mapping it will be ignored.\nMapping Refresh #  It is recommended that if a mapping is unused for 5 minutes it should be destroyed. This is entirely up to the ISP or hardware manufacturer.\nSTUN #  STUN(Session Traversal Utilities for NAT) is a protocol that was created just for working with NATs. This is another technology pre-dates WebRTC (and ICE!). It is defined by RFC 5389 STUN defines the structure of packets we send over UDP. The STUN protocol is also used by ICE/TURN.\nSTUN is useful because it gives us all the details about our NAT Mappings. We are able to create them, but we have no idea what the address is! STUN not only gives you the ability to create a mapping, but then you get the details so you can share it with others so they can send traffic to you via the mapping you created.\nLets start with a basic description of STUN. Later it will be extended later for TURN and ICE usage. For now we are just going to describe the Request/Response flow to create a mapping and then how we get the details of it to share with others. This is what actually happens when you have a stun: server in your ICE urls.\nProtocol Structure #  Every STUN packets begins with a STUN header, with the following structure\n 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |0 0| STUN Message Type | Message Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Magic Cookie | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | | Transaction ID (96 bits) | | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ STUN Message Type #  Each STUN packet has a type. For now we only care about the following. We make a request to a STUN server, and it responds with a different type.\n Binding Request - 0x0001 Binding Response - 0x0101  Message Length #  This is how long the Data section is. This section contains arbitrary data that is defined by the Message Type\nMagic Cookie #  The fixed value 0x2112A442, it helps distinguish STUN traffic from other protocols.\nTransaction ID #  96-bit identifier that uniquely identifies a request/response. This helps you pair up your requests and responses.\nData #  Data will contain a list of STUN attributes. A STUN Attribute has the following structure.\n0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type | Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Value (variable) .... +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ The STUN Binding Request uses no attributes.\nThe STUN Binding Response uses a XOR-MAPPED-ADDRESS (0x0020). This attribute contains an IP/Port. This is the IP/Port of the NAT Mapping that is created!\nCreate a NAT Mapping #  Creating a NAT Mapping using STUN just takes sending one request! You send a STUN Binding Request to the STUN Server. The STUN Server then responds with a STUN Binding Response. This STUN Binding Response will contain the Mapped Address. This Mapped Address is what you would share if someone wanted to send packets to you.\nThis how a Server Reflexive Candidate is generated also known as your Public IP.\nDetermining NAT Type #  Unfortunately the Mapped Address might not be useful in all cases. If it is Address Dependent only the STUN server can send traffic back to you, making it useless for communicating with others.\nRFC5780 defines a method for running a test to determine your NAT Type. This would be useful because you would know ahead of time if direct connectivity was possible, or if you need to use a TURN Server.\nTURN #  TURN (Traversal Using Relays around NAT) is defined in RFC5766 is the solution when direct connectivity isn\u0026rsquo;t possible. It could be because you have two NAT Types that are incompatible, or maybe can\u0026rsquo;t speak the same protocol! TURN is also important for privacy purposes. By running all your communication through TURN you obscure the clients actual address.\nTURN uses a dedicated server. This server acts as a proxy for a client. The client connects to a TURN Server and creates an Allocation. By creating a Allocation a client gets a temporary IP/Port/Protocol that can send into to get traffic back to the client. This new listener is known as the Relayed Transport Address. Think of it like a forwarding address! Anything you send into this is forwarded to the client. Also the client then sends packets via the Relayed Transport Address.\nTURN Lifecycle #  The following is everything that a client who wishes to create a TURN allocation has to do. Communicating with someone who is using TURN requires no changes though, you get a IP/Port and communicate with it like any other host.\nAllocations #  Allocations are at the core of TURN. A Allocation is basically a \u0026lsquo;TURN Session\u0026rsquo;. To create a TURN allocation you communicate with the TURN control port (usually 3478)\nWhen creating an allocation you need to provide/decide a few things\n Username/Password - Creating TURN allocations require authentication Allocation Transport - The Relayed Transport Address can be UDP or TCP  Permissions #  Send Indication/ChannelData #  TURN Usage #  One TURN Allocations for Communication #  Two TURN Allocations for Communication #  ICE #  ICE (Interactive Connectivity Establishment)\nCandidate Gathering #  Host #  Host (mDNS) #  Server Reflexive #  Relay #  Connectivity Checks #  Peer Reflexive Candidates #  Candidate Selection #  "});index.add({'id':3,'href':'/docs/04-securing/','title':"Securing",'section':"Docs",'content':"Securing #  DTLS #  SRTP #  "});index.add({'id':4,'href':'/docs/05-media-communication/','title':"Media Communication",'section':"Docs",'content':"Audio and Video Communication #  RTP/RTCP #  Protocol Basics Loss and Error Resilience Congestion Control\n"});index.add({'id':5,'href':'/docs/06-data-communication/','title':"Data Communication",'section':"Docs",'content':"SCTP #  "});index.add({'id':7,'href':'/docs/08-debugging/','title':"Debugging",'section':"Docs",'content':"Debugging #  Reduce Surface Area #  Network Debugging #  Media Debugging #  Data Debugging #  "});index.add({'id':8,'href':'/docs/09-history-of-webrtc/','title':"History",'section':"Docs",'content':"History #  This section is ongoing and we don’t have all the facts yet. We are conducting interviews and build a history of digital communication.\nPre-RTP #  RTP #  SDP #  ICE #  SRTP #  SCTP #  DTLS #  "});index.add({'id':9,'href':'/docs/10-faq/','title':"FAQ",'section':"Docs",'content':"FAQ #  "});})();